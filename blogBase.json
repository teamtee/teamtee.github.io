{"singlePage": ["about"], "startSite": "", "filingNum": "", "onePageListNum": 15, "commentLabelColor": "#006b75", "yearColorList": ["#bc4c00", "#0969da", "#1f883d", "#A333D0"], "i18n": "CN", "themeMode": "manual", "dayTheme": "light", "nightTheme": "dark_colorblind", "urlMode": "pinyin", "script": "", "style": "", "head": "", "indexScript": "", "indexStyle": "", "bottomText": "\u8f6c\u8f7d\u8bf7\u6ce8\u660e\u51fa\u5904", "showPostSource": 1, "iconList": {"music": "M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13Z"}, "UTC": 8, "rssSplit": "sentence", "exlink": {}, "needComment": 0, "allHead": "", "title": "teamtee", "subTitle": "\u8fd9\u91cc\u662f\u63d0\u59c6\u63d0\u7684\u5c0f\u5c4b", "avatarUrl": "https://github.githubassets.com/favicons/favicon.svg", "GMEEK_VERSION": "last", "displayTitle": "Teamtee", "homeUrl": "http://teamtee.top", "faviconUrl": "https://github.githubassets.com/favicons/favicon.svg", "email": "2624071330@qq.com", "primerCSS": "<link href='https://mirrors.sustech.edu.cn/cdnjs/ajax/libs/Primer/21.0.7/primer.css' rel='stylesheet' />", "postListJson": {"P1": {"htmlDir": "docs/post/ce-shi-yong.html", "labels": ["documentation"], "postTitle": "\u6d4b\u8bd5\u7528", "postUrl": "post/ce-shi-yong.html", "postSourceUrl": "https://github.com/teamtee/teamtee.github.io/issues/1", "commentNum": 0, "wordCount": 2, "description": "\u6d4b\u8bd5\u3002", "top": 0, "createdAt": 1733980072, "style": "", "script": "", "head": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-12-12", "dateLabelColor": "#bc4c00"}, "P2": {"htmlDir": "docs/post/shi-yong-Whisper-ti-qu-bu-ding-chang-du-de-te-zheng.html", "labels": ["QuickNote"], "postTitle": "\u4f7f\u7528Whisper\u63d0\u53d6\u4e0d\u5b9a\u957f\u5ea6\u7684\u7279\u5f81", "postUrl": "post/shi-yong-Whisper-ti-qu-bu-ding-chang-du-de-te-zheng.html", "postSourceUrl": "https://github.com/teamtee/teamtee.github.io/issues/2", "commentNum": 0, "wordCount": 4321, "description": "\r\n\r\n[Whisper\u7684PT\u6587\u4ef6\u4e0b\u8f7d\u5730\u5740](https://gitcode.csdn.net/65ed73ad1a836825ed799909.html)\r\n[\u5728Colab\u5fae\u8c03Whisper](https://huggingface.co/blog/fine-tune-whisper)\r\n\r\n## Whisper\u7b80\u4ecb\r\n\r\nWhisper\u662fOpenai\u5f00\u53d1\u7684\u8bed\u97f3\u8bc6\u522b\u5de5\u5177\uff0c\u901a\u5e38\u6211\u4eec\u53ef\u4ee5\u7528Whisper\u5e93\u6216\u8005Transformers\u6765\u4f7f\u7528Whisper\uff0c\u672c\u6587\u4e13\u6ce8\u4e8eWhisper\u5e93\u7684\u4f7f\u7528\uff0c\u5b89\u88c5\u65b9\u5f0f\u5982\u4e0b\r\n\r\n```python\r\npip install -U openai-whisper\r\n```\r\n\r\n\u8fd8\u9700\u8981\u5b89\u88c5ffmpeg\r\n```\r\nconda install ffmpeg(\u652f\u6301\u975esudo\u7528\u6237)\r\nsudo apt install ffmpeg \r\n```\r\n\r\nWhisper\u5305\u542bencoder\u548cdecoder\u4e24\u4e2a\u90e8\u5206,encoder\u63a5\u53d730s\u7684\u97f3\u9891\u957f\u5ea6\u7684\u8f93\u51fa\uff0c\u7f16\u7801\u6210\u4e3a\u7279\u5f81\u5411\u91cf\uff0cdecoder\u8d1f\u8d23\u89e3\u7801\r\n\r\n\r\n## Whisper\u8bc6\u522b\r\n`transcribe`:\r\n- \u6700\u7b80\u5355\u7684\u8bc6\u522b\u65b9\u5f0f\r\n```python\r\nimport whisper\r\nmodel = whisper.load('path/name')\r\ntext = model.transcribe('wav_path')\r\n\r\n```\r\n`decode`\uff1a\r\n- \u6ce8\u610f\u5230\u97f3\u9891\u4f1a\u88ab`pad_or_trim`\u51fd\u6570\u586b\u5145\u6216\u8005\u88c1\u526a\u4e3a30s\u957f\u5ea6\r\n- `decode`\u652f\u6301`mel`\u8f93\u5165\u6216\u8005`encoder`\u7f16\u7801\u540e\u7684\u7279\u5f81\u8f93\u5165\r\n- `nmels=80/128`,128\u9002\u5408v3\uff0c80\u9002\u5408\u5176\u4ed6\u7248\u672c\r\n```python\r\nimport whisper\r\nimport numpy as np\r\nmodel = whisper.load_model('')\r\naudio = whisper.load_audio('')\r\naudio = whisper.pad_or_trim(audio)\r\nmel = whisper.log_mel_spectrogram(audio,n_mels=model.dims.n_mels).to('cuda').to(model.device)\r\nresult = model.decode(mel)\r\n# result = whisper.decode(model, mel)\r\n\r\n\r\n```\r\n\r\n```python\r\nimport whisper\r\nimport numpy as np\r\nmodel = whisper.load_model('')\r\naudio = whisper.load_audio('')\r\naudio = whisper.pad_or_trim(audio)\r\nmel = whisper.log_mel_spectrogram(audio,n_mels=model.dims.n_mels).to('cuda').to(model.device)\r\nresult =model.decode(mel)\r\nencoder_output = model.encoder(mel.unsqueeze(0))\r\n\r\nresult = model.decode(encoder_output)\r\n# result = whisper.decode(model, encoder_output)\r\n# \u6253\u5370encoder\u8f93\u51fa\u7684\u5f62\u72b6\r\n```\r\n## Whisper\u63d0\u53d6\u7279\u5f81\r\n\u5982\u679c\u91c7\u7528whisper\u7684encoder\u63d0\u53d6\u7279\u5f81\uff0c\u97f3\u9891\u9996\u5148\u8981\u88ab\u586b\u5145\u523030s\r\n```python\r\nimport whisper\r\nimport numpy as np\r\nmodel = whisper.load_model('')\r\naudio = whisper.load_audio('')\r\naudio = whisper.pad_or_trim(audio)\r\nmel = whisper.log_mel_spectrogram(audio,n_mels=model.dims.n_mels).to('cuda').to(model.device)\r\nresult =model.decode(mel)\r\nencoder_output = model.encoder(mel.unsqueeze(0))\r\n\r\n```\r\n\r\n\u53ef\u4ee5\u91c7\u7528\u66ff\u4ee3forward\u51fd\u6570\u7684\u65b9\u6cd5\u6765\u63d0\u53d6\u4e0d\u5b9a\u957f\u5ea6\u7684\u7279\u5f81,\u56e0\u4e3aencoder\u4e0d\u652f\u6301\u5c0f\u4e8e30s\u957f\u5ea6\u97f3\u9891\u7684\u539f\u56e0\u5728\u4e8e\r\n- `x = (x + self.positional_embedding).to(x.dtype)`\r\n\r\n```python\r\nimport types\r\nimport whisper\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\ndef whisper_encoder_forward_monkey_patch(self, x: torch.Tensor):\r\n\t'''\r\n\tx : torch.Tensor, shape = (batch_size, n_mels, n_ctx)\r\n\tthe mel spectrogram of the audio\r\n\t'''\r\n\tx = F.gelu(self.conv1(x))\r\n\tx = F.gelu(self.conv2(x))\r\n\tx = x.permute(0, 2, 1)\r\n\t# assert x.shape[1:] == self.positional_embedding.shape, 'incorrect audio shape'\r\n\t# x = (x + self.positional_embedding).to(x.dtype)\r\n\tx = (x + self.positional_embedding[: x.shape[1]]).to(x.dtype)\r\n\tfor block in self.blocks:\r\n\t\tx = block(x)\r\n\t\tx = self.ln_post(x)\r\n\treturn x\r\n```\r\n\r\n```python\r\n\r\nencoder = whisper.load_model('base').encoder\r\nencoder.whisper_encoder_forward_monkey_patch = types.MethodType(whisper_encoder_forward_monkey_patch, encoder)\r\naudio_path = ''\r\naudio = whisper.load_audio(audio_path)\r\nmel = whisper.log_mel_spectrogram(audio).to(model.device)\r\nfeatures = encoder.whisper_encoder_forward_monkey_patch(mel.unsqueeze(0))\r\n```\r\n\r\n```python\r\nwhisper.model.AudioEncoder.forward = forward\r\nmodel = whisper.load_model('')\r\naudio = whisper.load_audio('')\r\nmel = whisper.log_mel_spectrogram(audio,n_mels=model.dims.n_mels).to('cuda').to(model.device).unsquenze(0)\r\noutout = model.encoder(mel)\r\n```\r\n\u5982\u679c\u9700\u8981whisper\u63d0\u53d6\u51fa\u7684\u8be5\u7279\u5f81\u8fdb\u884c\u89e3\u7801\uff0c\u5fc5\u987b\u4f7f\u7528options\r\n\r\n```python\r\noptions = whisper.DecodingOptions(\r\n\u00a0 \u00a0 task='transcribe',\r\n\u00a0 \u00a0 language='zh',\r\n\u00a0 \u00a0 without_timestamps=True,\r\n\u00a0 \u00a0 beam_size=4,\r\n\r\n)\r\nprint(whisper.decode(model,mel,options))\r\n```\r\n\r\n## Whisper Options\r\n- `task`:\u9ed8\u8ba4\u4e3a`transcribe`\uff0c\u53ef\u4ee5\u8bbe\u7f6e\u4e3a`translate`,\u5373\u4e3a\u5c06\u8f93\u51fa\u7ffb\u8bd1\u4e3a\u82f1\u8bed\r\n\r\n\r\n\r\n## Huggingface\u7528\u6cd5\r\n```python\r\nfrom transformers import WhisperForConditionalGeneration, WhisperProcessor\r\n# \u52a0\u8f7d\u9884\u8bad\u7ec3\u7684Whisper\u6a21\u578b\u548c\u5904\u7406\u5668\r\nmodel = WhisperForConditionalGeneration.from_pretrained('openai/whisper-base')\r\nprocessor = WhisperProcessor.from_pretrained('openai/whisper-base')\r\n# \u5047\u8bbe\u4f60\u6709\u4e00\u4e2a\u8f93\u5165\u7684\u8bed\u97f3\u7279\u5f81\r\ninput_features = ...  # \u8fd9\u91cc\u5e94\u8be5\u662f\u9884\u5904\u7406\u540e\u7684\u8bed\u97f3\u7279\u5f81\r\n# \u5c06\u8f93\u5165\u7279\u5f81\u79fb\u52a8\u5230\u6a21\u578b\u6240\u5728\u7684\u8bbe\u5907\u4e0a\r\ninput_features = input_features.to(model.device)\r\n# \u4f7f\u7528\u5206\u5757\u7b97\u6cd5\u751f\u6210\u8f93\u51fa\r\noutputs = model.generate(\r\n    input_features=input_features,\r\n    return_dict_in_generate=True,\r\n    output_hidden_states=True,\r\n    chunk_length=30,  # \u8bbe\u7f6e\u5206\u5757\u957f\u5ea6\r\n    stride_length=15  # \u8bbe\u7f6e\u6b65\u957f\r\n)\r\n# \u89e3\u7801\u751f\u6210\u7684\u5e8f\u5217\r\ntranscriptions = processor.batch_decode(outputs.sequences, skip_special_tokens=True)[0]\r\n# \u6253\u5370\u8f6c\u5f55\u7ed3\u679c\r\nprint(transcriptions)\r\n\r\n```\u3002", "top": 0, "createdAt": 1733993645, "style": "", "script": "", "head": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-12-12", "dateLabelColor": "#bc4c00"}}, "singeListJson": {}, "labelColorDict": {"bug": "#d73a4a", "duplicate": "#cfd3d7", "enhancement": "#a2eeef", "good first issue": "#7057ff", "help wanted": "#008672", "invalid": "#e4e669", "question": "#d876e3", "QuickNote": "#0075ca", "wontfix": "#ffffff"}, "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "prevUrl": "disabled", "nextUrl": "disabled"}